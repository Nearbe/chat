"""
–°–∫—Ä–∏–ø—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ Chat –≤ Qdrant –¥–ª—è RAG-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç SKILL.md —Ñ–∞–π–ª—ã, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –∫–æ–¥ Swift
"""

import json
from pathlib import Path
from typing import List, Dict, Any
import qdrant_client
from qdrant_client.models import Distance, VectorParams, PointStruct
import hashlib

# –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É Chat
CHAT_PROJECT_PATH = Path(__file__).parent.parent


class QdrantIndexer:
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ Qdrant –¥–ª—è RAG-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è MCP Memory Server –∏ LangGraph Orchestrator
    """

    def __init__(self, qdrant_url: str = "http://localhost:6333"):
        self.client = qdrant_client.QdrantClient(host=qdrant_url.split(":")[0], port=int(qdrant_url.split(":")[1]))
        self.collection_name_code = "chat_code"
        self.collection_name_docs = "chat_docs"
        self.embedding_dim = 768  # nomic-embed-text

    def _generate_vector_id(self, file_path: str) -> int:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞"""
        hash_obj = hashlib.md5(file_path.encode())
        return int(hash_obj.hexdigest()[:8], 16)

    def _create_collections(self) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π –≤ Qdrant –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –∫–æ–¥–∞ Swift
        if not self.client.collection_exists(self.collection_name_code):
            self.client.create_collection(
                collection_name=self.collection_name_code,
                vectors_config=VectorParams(size=self.embedding_dim, distance=Distance.COSINE),
            )
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name_code}")

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        if not self.client.collection_exists(self.collection_name_docs):
            self.client.create_collection(
                collection_name=self.collection_name_docs,
                vectors_config=VectorParams(size=self.embedding_dim, distance=Distance.COSINE),
            )
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name_docs}")

    def _embed_text(self, text: str) -> list:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        –í production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SentenceTransformer –∏–ª–∏ API Qdrant
        –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä (–∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π)
        """
        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SentenceTransformer("nomic-embed-text")
        # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ - –∑–∞–≥–ª—É—à–∫–∞
        import random
        return [random.uniform(-1, 1) for _ in range(self.embedding_dim)]

    def index_swift_files(self, project_path: Path = None) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö Swift —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        if not project_path:
            project_path = CHAT_PROJECT_PATH

        swift_files = list(project_path.rglob("*.swift"))
        print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(swift_files)} Swift —Ñ–∞–π–ª–æ–≤")

        points = []
        for file_path in swift_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                embedding = self._embed_text(content)

                point = PointStruct(
                    id=self._generate_vector_id(str(file_path)),
                    vector=embedding,
                    payload={
                        "file_path": str(file_path),
                        "language": "swift",
                        "size": len(content),
                        "type": "code",
                        "directory": str(file_path.parent),
                    }
                )
                points.append(point)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {file_path}: {e}")

        # Batch upsert –≤ Qdrant
        if points:
            self.client.upsert(
                collection_name=self.collection_name_code,
                points=points,
            )
            print(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(points)} Swift —Ñ–∞–π–ª–æ–≤")

        return len(points)

    def index_documentation(self, project_path: Path = None) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (SKILL.md, README.md, *.md —Ñ–∞–π–ª—ã)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        if not project_path:
            project_path = CHAT_PROJECT_PATH

        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö MD —Ñ–∞–π–ª–æ–≤
        md_files = list(project_path.rglob("*.md"))
        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(md_files)} Markdown —Ñ–∞–π–ª–æ–≤")

        points = []
        for file_path in md_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                embedding = self._embed_text(content)

                point = PointStruct(
                    id=self._generate_vector_id(str(file_path)),
                    vector=embedding,
                    payload={
                        "file_path": str(file_path),
                        "type": "documentation",
                        "size": len(content),
                        "directory": str(file_path.parent),
                    }
                )
                points.append(point)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {file_path}: {e}")

        # Batch upsert –≤ Qdrant
        if points:
            self.client.upsert(
                collection_name=self.collection_name_docs,
                points=points,
            )
            print(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(points)} Markdown —Ñ–∞–π–ª–æ–≤")

        return len(points)

    def index_agents_mapping(self) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è agents_mapping.json –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤
        """
        mapping_path = CHAT_PROJECT_PATH / "agents_mapping.json"

        if not mapping_path.exists():
            print(f"‚ö†Ô∏è –§–∞–π–ª {mapping_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return 0

        try:
            content = mapping_path.read_text(encoding='utf-8')
            embedding = self._embed_text(content)

            point = PointStruct(
                id=self._generate_vector_id(str(mapping_path)),
                vector=embedding,
                payload={
                    "file_path": str(mapping_path),
                    "type": "configuration",
                    "size": len(mapping_path.read_text()),
                    "description": "–ú–∞–ø–ø–∏–Ω–≥ 30+ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"
                }
            )

            self.client.upsert(
                collection_name=self.collection_name_docs,
                points=[point],
            )
            print(f"‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω agents_mapping.json")
            return 1
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            return 0

    def search_code(self, query: str, top_k: int = 5) -> list:
        """
        –ü–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É –≤ Qdrant (RAG –¥–ª—è LangGraph)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-K –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self._embed_text(query)

        # –ü–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ code
        results = self.client.search(
            collection_name=self.collection_name_code,
            query_vector=query_embedding,
            limit=top_k,
        )

        return [
            {
                "file_path": hit.payload["file_path"],
                "score": hit.score,
                "size": hit.payload["size"],
                "directory": hit.payload["directory"],
            }
            for hit in results
        ]

    def search_docs(self, query: str, top_k: int = 5) -> list:
        """
        –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ Qdrant (RAG –¥–ª—è LangGraph)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-K –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self._embed_text(query)

        # –ü–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ docs
        results = self.client.search(
            collection_name=self.collection_name_docs,
            query_vector=query_embedding,
            limit=top_k,
        )

        return [
            {
                "file_path": hit.payload["file_path"],
                "score": hit.score,
                "size": hit.payload["size"],
                "type": hit.payload.get("type", "documentation"),
            }
            for hit in results
        ]

    def run_full_indexation(self) -> dict:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤ Qdrant
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        """
        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π
        self._create_collections()

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è Swift —Ñ–∞–π–ª–æ–≤
        swift_count = self.index_swift_files()

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        docs_count = self.index_documentation()

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è agents_mapping.json
        mapping_count = self.index_agents_mapping()

        total = swift_count + docs_count + mapping_count

        print(f"\n‚úÖ –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  - Swift —Ñ–∞–π–ª—ã: {swift_count}")
        print(f"  - Markdown —Ñ–∞–π–ª—ã: {docs_count}")
        print(f"  - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {mapping_count}")
        print(f"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print(f"  –ò—Ç–æ–≥–æ: {total} —Ñ–∞–π–ª–æ–≤")

        return {
            "swift_files": swift_count,
            "markdown_files": docs_count,
            "configuration": mapping_count,
            "total": total
        }

    def health_check(self) -> dict:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è Qdrant –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–π
        """
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö
            code_collection = self.client.get_collection(self.collection_name_code)
            docs_collection = self.client.get_collection(self.collection_name_docs)

            return {
                "status": "healthy",
                "collections": {
                    self.collection_name_code: {
                        "points_count": code_collection.points_count,
                        "vectors_count": code_collection.vectors_count,
                        "indexed_at": code_collection.updated_at if hasattr(code_collection, 'updated_at') else None
                    },
                    self.collection_name_docs: {
                        "points_count": docs_collection.points_count,
                        "vectors_count": docs_collection.vectors_count,
                        "indexed_at": docs_collection.updated_at if hasattr(docs_collection, 'updated_at') else None
                    }
                }
            }
        except Exception as e:
            return {
                "status": "error",
                "message": str(e)
            }


# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞ Qdrant...")

    indexer = QdrantIndexer(qdrant_url="http://localhost:6333")

    # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    stats = indexer.run_full_indexation()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
    health = indexer.health_check()
    print(f"\nüè• –ó–¥–æ—Ä–æ–≤—å–µ Qdrant:")
    print(json.dumps(health, indent=2, ensure_ascii=False))

    # –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞
    print("\nüîç –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:")
    results = indexer.search_docs("SwiftUI View", top_k=3)
    for result in results:
        print(f"  - {result['file_path']} (score: {result['score']:.2f})")
